{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.json\", \"r\") as fh:\n",
    "    config = json.load(fh)\n",
    "base_path = Path(config[\"base_path\"])\n",
    "base_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polders, restoration sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_WITHIN_M = (\n",
    "    5_000  # distance for selection of polder-to-restoration-site relations (in metres)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_polders = geopandas.read_file(\n",
    "    base_path / \"infrastructure\" / \"protectedPolders\" / \"Polders_selected.shp\",\n",
    "    engine=\"pyogrio\",\n",
    ")\n",
    "\n",
    "protected_polders_9678 = protected_polders.to_crs(epsg=9678)\n",
    "protected_polders_4326 = protected_polders.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protected_polders.polder_ID.unique()), len(protected_polders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_sites = geopandas.read_file(\n",
    "    base_path\n",
    "    / \"nature-ecosystems\"\n",
    "    / \"Potential Mangrove Restoration Sites\"\n",
    "    / \"potential_sites_epsg9678.gpkg\",\n",
    "    engine=\"pyogrio\",\n",
    ").explode(index_parts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_sites[\"potential_site_id\"] = range(len(restoration_sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_sites.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restoration_sites_buf = restoration_sites.copy()\n",
    "restoration_sites_buf.geometry = restoration_sites.buffer(DISTANCE_WITHIN_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_polder_intersection = (\n",
    "    restoration_sites_buf.sjoin(\n",
    "        protected_polders_9678, how=\"left\", predicate=\"intersects\"\n",
    "    )[[\"potential_site_id\", \"polder_ID\"]]\n",
    "    .sort_values(by=\"polder_ID\")\n",
    "    .reset_index(drop=True)\n",
    "    .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_link_polders = geopandas.GeoDataFrame(\n",
    "    site_polder_intersection.sort_values(by=\"potential_site_id\")\n",
    "    .groupby(\"potential_site_id\")\n",
    "    .agg(lambda d: sorted(d))\n",
    "    .join(\n",
    "        restoration_sites.set_index(\"potential_site_id\").drop(columns=[\"mean\", \"class\"])\n",
    "    ),\n",
    "    crs=restoration_sites.crs,\n",
    ")\n",
    "sites_link_polders.to_file(\n",
    "    \"../scratch/potential_sites_with_polders.gpkg\", driver=\"GPKG\", engine=\"pyogrio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each site is within DISTANCE_WITHIN_M of a set of one or more polders\n",
    "# that may be protected if the site is restored\n",
    "# (site 1 may protect polders A and B, site 2 => polder C)\n",
    "site_to_polders = defaultdict(set)\n",
    "# this is all the different sets of polders that are within DISTANCE_WITHIN_M\n",
    "# of any potential site\n",
    "# (polders A and B or polder C)\n",
    "polder_sets = set()\n",
    "# each set of polders is within DISTANCE_WITHIN_M of a set of sites that\n",
    "# may protect them\n",
    "# (polders A and B may be protected by site 1, polder C => site 2)\n",
    "polder_set_to_sites = defaultdict(set)\n",
    "\n",
    "lookup = site_polder_intersection.set_index(\"potential_site_id\")\n",
    "for site in site_polder_intersection.potential_site_id.unique():\n",
    "    site_polders = lookup.loc[site, \"polder_ID\"]\n",
    "    if isinstance(site_polders, str):\n",
    "        polder_set = frozenset([site_polders])\n",
    "    else:\n",
    "        polder_set = frozenset(site_polders)\n",
    "    site_to_polders[site] = polder_set\n",
    "    polder_sets.add(polder_set)\n",
    "    polder_set_to_sites[polder_set].add(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polder_site_relations = []\n",
    "for polders, sites in polder_set_to_sites.items():\n",
    "    polder_site_relations.append(\n",
    "        {\n",
    "            \"polder_set\": sorted(polders),\n",
    "            \"sites_protecting\": sorted(int(s) for s in sites),\n",
    "        }\n",
    "    )\n",
    "with open(\"../scratch/polder_site_relations.json\", \"w\") as fh:\n",
    "    json.dump(polder_site_relations, fh, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature polder intersection\n",
    "\n",
    "To find potential benefit or assets-at-risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_feature_damages(\n",
    "    base_path, hazard, sector, infrastructure_path, damage_path, polders\n",
    "):\n",
    "    # print(\"*\", hazard, sector)\n",
    "    fpath = base_path / infrastructure_path\n",
    "    fpi_path = Path(\"../scratch\") / f\"{fpath.name}.pq\"\n",
    "    if not fpi_path.exists():\n",
    "        features = (\n",
    "            geopandas.read_file(\n",
    "                base_path / infrastructure_path, engine=\"pyogrio\", fid_as_index=True\n",
    "            )\n",
    "            .reset_index()\n",
    "            .to_crs(epsg=4326)\n",
    "        )\n",
    "        # print(\"read features\", len(features))\n",
    "        feature_polder_intersection = features.sjoin(\n",
    "            polders[[\"polder_ID\", \"geometry\"]], how=\"inner\", predicate=\"intersects\"\n",
    "        ).reset_index(drop=True)\n",
    "        # print(\"intersected features\", len(feature_polder_intersection))\n",
    "        # print(\"unique fid\", len(feature_polder_intersection.fid.unique()))\n",
    "        feature_polder_intersection.to_parquet(fpi_path)\n",
    "    else:\n",
    "        feature_polder_intersection = geopandas.read_parquet(fpi_path)\n",
    "        # print(\"read intersected features\", len(feature_polder_intersection))\n",
    "\n",
    "    dpath = base_path / damage_path\n",
    "    dpi_path = Path(\"../scratch\") / f\"{dpath.name}.pq\"\n",
    "    if not dpi_path.exists():\n",
    "        damage = pandas.read_csv(base_path / damage_path).set_index(\"fid\")\n",
    "        # print(\"read damage\", len(damage))\n",
    "\n",
    "        try:\n",
    "            damage_polder_intersection = damage.loc[feature_polder_intersection.fid]\n",
    "        except KeyError as e:\n",
    "            # print(\"Warning: Ignoring invalid keys (features not present in calculated damages)\")\n",
    "            valid_fid = damage.index.intersection(feature_polder_intersection.fid)\n",
    "            damage_polder_intersection = damage.loc[valid_fid]\n",
    "        # print(\"polder damage\", len(damage_polder_intersection))\n",
    "\n",
    "        damage_columns = [\n",
    "            c for c in damage_polder_intersection.columns if \"Damage\" in c\n",
    "        ]\n",
    "\n",
    "        df_damage = damage_polder_intersection[damage_columns]\n",
    "        mask = df_damage.max(axis=1) > 0\n",
    "        damage_polder_intersection_nonzero_damage = damage_polder_intersection[mask]\n",
    "        # print(\"filtered damage\", len(damage_polder_intersection_nonzero_damage))\n",
    "\n",
    "        damage_polder_intersection_nonzero_damage.to_parquet(dpi_path)\n",
    "    else:\n",
    "        damage_polder_intersection_nonzero_damage = pandas.read_parquet(dpi_path)\n",
    "        # print(\"read filtered damage\", len(damage_polder_intersection_nonzero_damage))\n",
    "\n",
    "    return feature_polder_intersection, damage_polder_intersection_nonzero_damage\n",
    "\n",
    "\n",
    "metadata = pandas.read_csv(\"infra-damage.csv\")\n",
    "summary_dfs = []\n",
    "for row in metadata.itertuples():\n",
    "    _, hazard, sector, infrastructure_path, damage_path = row\n",
    "    print(hazard, sector)\n",
    "    feature_polder_intersection, damage_polder_intersection = read_feature_damages(\n",
    "        base_path,\n",
    "        hazard,\n",
    "        sector,\n",
    "        infrastructure_path,\n",
    "        damage_path,\n",
    "        protected_polders_4326,\n",
    "    )\n",
    "    feature_polder_intersection[\n",
    "        \"length_m\"\n",
    "    ] = feature_polder_intersection.geometry.to_crs(epsg=9678).length\n",
    "\n",
    "    features = feature_polder_intersection[[\"fid\", \"polder_ID\", \"length_m\"]].set_index(\n",
    "        \"fid\"\n",
    "    )\n",
    "    damage_columns = [c for c in damage_polder_intersection.columns if \"Damage\" in c]\n",
    "    damage = damage_polder_intersection[damage_columns]\n",
    "\n",
    "    df = (\n",
    "        features.join(damage)\n",
    "        .reset_index()\n",
    "        .melt(\n",
    "            id_vars=[\"fid\", \"polder_ID\", \"length_m\"],\n",
    "            var_name=\"scenario\",\n",
    "            value_name=\"damage_euro\",\n",
    "        )\n",
    "    )\n",
    "    meta = df.scenario.str.extract(\n",
    "        r\"Damage_euro_(?P<epoch>\\w\\w\\w\\w)_?(?P<rcp>\\w+)?_rp(?P<rp>\\d+)\"\n",
    "    )\n",
    "    df = pandas.concat([df.drop(columns=[\"scenario\"]), meta], axis=1)\n",
    "    df.rcp = df.rcp.fillna(\"baseline\")\n",
    "    df.rp = df.rp.astype(int)\n",
    "    df[\"hazard\"] = hazard\n",
    "    df[\"sector\"] = sector\n",
    "    df[\"count\"] = 1\n",
    "    df[\"count_damaged\"] = df.damage_euro > 0\n",
    "    df[\"damaged_length_m\"] = df.length_m * df.count_damaged\n",
    "    summary = df.groupby(\n",
    "        by=[\"polder_ID\", \"hazard\", \"sector\", \"epoch\", \"rcp\", \"rp\"]\n",
    "    ).agg(\n",
    "        {\n",
    "            \"count\": \"sum\",\n",
    "            \"count_damaged\": \"sum\",\n",
    "            \"length_m\": \"sum\",\n",
    "            \"damaged_length_m\": \"sum\",\n",
    "            \"damage_euro\": \"sum\",\n",
    "        }\n",
    "    )\n",
    "    summary_dfs.append(summary)\n",
    "\n",
    "summary = pandas.concat(summary_dfs)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(\n",
    "    \"../scratch/polder_rp_damages.csv\", float_format=\"%.2f\"\n",
    ")  # output rounded to the cent !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
